
This project focuses on speech recognition using Connectionist Temporal Classification (CTC) and decoding strategies like Beam Search. 
The task involves transcribing speech recordings into sequences of phonemes. Unlike traditional frame-level labeling, where each frame is labeled independently, 
this project aims to generate more natural predictions by outputting phoneme sequences directly. The neural network architecture includes components like 1-D CNNs, Bi-LSTMs, 
and optionally, pyramidal Bi-LSTMs. Training involves aligning the output probabilities with the compressed, order-aligned phoneme sequences for loss computation and model optimization. 
The goal is to achieve accurate phoneme transcriptions from speech recordings.





![image](https://github.com/Leonard250/Speech-detection/assets/141337656/63b90233-2795-45c2-afea-b55452917533)

After running the notebook the last optimal result that was obtained in 4.0095 on notebook but on making submission to kaggle the notebook scored 4.41

BRIEF SUMMARY ABOUT THE PROJECT
